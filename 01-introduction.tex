Community detection is the problem of identifying cohesive groups of vertices, also known as clusters, in complex networks that minimize cuts and maximize internal density \cite{garza2019community}.\ignore{This problem finds applications in various domains, including drug discovery, protein annotation, topic exploration, anomaly detection, and criminal identification.} Communities identified are intrinsic when based on network topology alone, and are disjoint when each vertex belongs to only one community \cite{com-gregory10}. One of the difficulties in community detection is the lack of apriori knowledge on the number and size distribution of communities \cite{com-blondel08}.

Community detection finds applications in various domains. In drug discovery, it helps identify groups of similar compounds or target proteins, thereby facilitating the discovery of new therapeutic agents \cite{ma2019comparative, udrescu2020uncovering}. In the health domain, it aids in understanding the dynamics of groups susceptible to epidemic diseases \cite{salathe2010dynamics}, detecting diseases like lung cancer \cite{bechtel2005lung}, and categorizing tumor types using genomic datasets \cite{haq2016community}. Additionally, it has been applied to elucidate the structure and evolution of metabolic networks \cite{pfeiffer2005evolution, kim2009centralized}, Gene Regulatory Networks (GRNs) \cite{rivera2010nemo}, and Lateral Gene Transfer (LGT) networks \cite{popa2011directed}. Another significant application of community detection is in the analysis of human brain networks \cite{bullmore2009complex, he2010graph}. In ecological studies, it is used to determine if food webs are organized into compartments, where species within the same compartment frequently interact among themselves but have fewer interactions with species in different compartments \cite{krause2003compartments, rezende2009compartments, guimera2010origin}.

The \textit{Label Propagation Algorithm (LPA)}, also known as RAK, \cite{com-raghavan07} is a popular diffusion-based approach for identifying communities. It is faster and more scalable than the Louvain method \cite{com-blondel08}, another high-quality community detection algorithm, as it does not require repeated optimization steps and is easier to parallelize \cite{com-newman04, com-raghavan07}. Due to this, LPA has been used in a number of other graph problems and applications, such as, finding connected components \cite{stergiou2018shortcutting}, graph partitioning \cite{slota2014pulp, wang2014partition, meyerhenke2014partitioning, meyerhenke2016partitioning, meyerhenke2017parallel, bae2020label, akhremtsev2020high, slota2020scalable, zhang2020multilevel}, hypergraph partitioning \cite{henne2015label, gottesburen2021scalable}, graph coarsening \cite{valejo2020coarsening}, vertex reordering and graph compression \cite{boldi2011layered}, unsupervised part-of-speech tagging \cite{das2011unsupervised}, sectionalizing power systems \cite{aziz2023novel}. Further, Peng et al. \cite{peng2014accelerating} observe that, while LPA achieves lower modularity scores (a metric for assessing community quality \cite{com-newman04}) than the Louvain method --- a lower modularity score for LPA implies that it may struggle to properly cluster nodes that are not well-connected to any particular community--- it attains the highest Normalized Mutual Information (NMI) score when compared to the ground truth.

A large number of LPA variants have also been proposed \cite{li2015parallel, farnadi2015scalable, li2015detecting, shen2016topic, mohan2017scalable, zhang2017label, berahmand2018lp, ma2018psplpa, sattari2018spreading, zheng2018improved, xu2019distributed, zarei2020detecting, maleki2020dhlp, zhang2020lilpa, el2021wlni, roghani2021pldls, zhang2023large}. Existing studies on LPA propose a number of algorithmic optimizations and parallelization techniques, but there continue to be a number of issue with each implementation. Further, the race for AI development has caused the prices of GPUs to skyrocket. These issues, and the large applicability of LPA, motivates us to present GVE-LPA,\footnote{\url{https://github.com/puzzlef/rak-communities-openmp}} an efficient implementation of LPA for multicore architectures.

\ignore{In the past few years, there has been an unprecedented surge in the gathering of data and the depiction of their interconnections through graphs. This surge has underscored the need for devising efficient parallel algorithms tailored for identifying communities within massive networks. The significance of the multicore/shared memory environment in this context is paramount, owing to its energy-efficient nature and the prevalence of hardware equipped with substantial DRAM capacities.\ignore{Optimizing parallel community detection algorithms for modern hardware architectures can yield notable performance benefits and competitive advantages across applications. However, many of the current algorithms for community detection are challenging to parallelize due to their irregular and inherently sequential nature \cite{com-halappanavar17}, in addition to the complexities of handling concurrency, optimizing data access, reducing contention, minimizing load imbalance.} Existing studies on LPA propose algorithmic optimizations and parallelization techniques, but do not study efficient data structures for picking the most weighted label, to the best of our knowledge. Moreover, the proposed techniques are scattered over a number of papers\ignore{, making it difficult for a reader to get a grip over them}.}




\ignore{\subsection{Our Contributions}}

\ignore{This report introduces GVE-LPA\footnote{https://github.com/puzzlef/rak-communities-openmp}, an optimized parallel implementation of LPA for shared memory multicores. On a machine with two 16-core Intel Xeon Gold 6226R processors, GVE-LPA outperforms FLPA, igraph LPA, and NetworKit LPA by $139\times$, $97000\times$, and $40\times$ respectively. GVE-LPA is on average $5.4\times$ faster than GVE-Louvain, and achieves a processing rate of $1.4 B$ edges/s on a $3.8 B$ edge graph. With doubling of threads, GVE-LPA exhibits an average performance scaling of $1.7\times$.}




%% - Use --- for a dash.
%% - Use ``camera-ready'' for quotes.
%% - Use {\itshape very} or \textit{very} for italicized text.
%% - Use \verb|acmart| or {\verb|acmart|} for mono-spaced text.
%% - Use \url{https://capitalizemytitle.com/} for URLs.
%% - Use {\bfseries Do not modify this document.} for important boldface details.
%% - Use \ref{fig:name} for referencing.

%% For a block of pre-formatted text: 
% \begin{verbatim}
%   \renewcommand{\shortauthors}{McCartney, et al.}
% \end{verbatim}

%% For a list of items:
% \begin{itemize}
% \item the ``ACM Reference Format'' text on the first page.
% \item the ``rights management'' text on the first page.
% \item the conference information in the page header(s).
% \end{itemize}

%% For a table:
% \begin{table}
%   \caption{Frequency of Special Characters}
%   \label{tab:freq}
%   \begin{tabular}{ccl}
%     \toprule
%     Non-English or Math&Frequency&Comments\\
%     \midrule
%     \O & 1 in 1,000& For Swedish names\\
%     $\pi$ & 1 in 5& Common in math\\
%     \$ & 4 in 5 & Used in business\\
%     $\Psi^2_1$ & 1 in 40,000& Unexplained usage\\
%   \bottomrule
% \end{tabular}
% \end{table}

%% For a full-width table:
% \begin{table*}
%   \caption{Some Typical Commands}
%   \label{tab:commands}
%   \begin{tabular}{ccl}
%     \toprule
%     Command &A Number & Comments\\
%     \midrule
%     \texttt{{\char'134}author} & 100& Author \\
%     \texttt{{\char'134}table}& 300 & For tables\\
%     \texttt{{\char'134}table*}& 400& For wider tables\\
%     \bottomrule
%   \end{tabular}
% \end{table*}


%% For inline math:
% \begin{math}
%   \lim_{n\rightarrow \infty}x=0
% \end{math},

%% For a numbered equation:
% \begin{equation}
%   \lim_{n\rightarrow \infty}x=0
% \end{equation}

%% For an unnumbered equation:
% \begin{displaymath}
%   \sum_{i=0}^{\infty} x + 1
% \end{displaymath}

%% For a figure:
% \begin{figure}[h]
%   \centering
%   \includegraphics[width=\linewidth]{inc/sample-franklin}
%   \caption{1907 Franklin Model D roadster. Photograph by Harris \&
%     Ewing, Inc. [Public domain], via Wikimedia
%     Commons. (\url{https://goo.gl/VLCRBB}).}
%   \Description{A woman and a girl in white dresses sit in an open car.}
% \end{figure}

%% For a teaser figure.
% \begin{teaserfigure}
%   \includegraphics[width=\textwidth]{sampleteaser}
%   \caption{figure caption}
%   \Description{figure description}
% \end{teaserfigure}
