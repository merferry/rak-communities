\subsection{Optimizations for LPA}
\label{sec:lpa}

We use a parallel implementation of LPA and experiment with different optimizations and parameter settings. We use the \textit{asynchronous} version of LPA, wherein threads operate independently on distinct regions of the graph. This facilitates quicker convergence, but may introduce greater variability in the final result. Further, we observe that parallel LPA obtains communities of higher quality than its sequential implementation, possibly due to randomization. We allocate a separate hashtable per thread to keep track of the total weight of each unique label linked to a vertex.

Our optimizations include using OpenMP's \verb|dynamic| loop schedule, setting an initial tolerance of $0.05$, enabling vertex pruning, employing the strict version of LPA, and using fast collision-free per-thread hashtables which are well separated in their memory addresses (\textit{Far-KV}). See below for the details on each optimization.

We evaluate multiple alternatives for each optimization, and show the relative time and the relative modularity of communities obtained by each alternative in Figure \ref{fig:rak-opt}. We perform these tests on every graph in the dataset (refer to Table \ref{tab:dataset}), conducting them five times on each graph to minimize the influence of noise. We then calculate the geometric mean for the runtime and arithmetic mean for the modularity, and represent them as ratios within each optimization category.


\subsubsection{Adjusting OpenMP loop schedule}

We attempt \textit{static}, \textit{dynamic}, \textit{guided}, and \textit{auto} loop scheduling approaches of OpenMP (each with a chunk size of $2048$) to parallelize LPA. We consider OpenMP's \verb|dynamic| loop schedule to be the best choice, due to its ability of work balancing among threads, and because it yields a runtime reduction of $27\%$ when compared to OpenMP's \textit{auto} loop schedule, while incurring only a $0.7\%$ reduction in the modularity of obtained communities (likely to be just noise).


\subsubsection{Limiting the number of iterations}

Restricting the number of iterations of LPA can ensure its termination within a reasonable number of iterations, but choosing a small limit may worsen the quality of communities obtained. Our results suggest that limiting the maximum number of iterations to $20$ strikes a good balance between runtime and modularity.


\subsubsection{Adjusting tolerance}

Using a small tolerance allows the algorithm to explore broader possibilities for community assignments, but comes at the cost of increased runtime. We find an initial tolerance of $0.05$ to be suitable. A tolerance of $0.1$ may also be acceptable, but provides a very small gain in performance when compared to a tolerance of $0.05$.


\subsubsection{Vertex pruning}

Vertex pruning is a method utilized to minimize unnecessary computation. In this approach, when a vertex alters its community, it assigns its neighbors for processing. Once a vertex has been processed, it is labeled as ineligible for further processing. However, this procedure incurs an additional overhead due to the marking and unmarking of vertices. Based on our findings, the employment of vertex pruning justifies this overhead and results in a performance enhancement of $17\%$. An illustration of vertex pruning optimization is shown in Figure \ref{fig:rak-pruning}.

\input{src/fig-rak-pruning}


\subsubsection{Picking the best label}

When there exist multiple labels connected to a vertex with maximum weight, we may randomly pick one of them (non-strict LPA), or pick only the first of them (strict LPA). We implement non-strict LPA using a simple modulo operator on the label id, as we observe that using \textit{xorshift} based random number generator does not provide any advantage. Results indicate that the strict version of LPA is $1.5\times$ faster than the non-strict approach, while also offering a gain in modularity of $2.1\%$.


\subsubsection{Hashtable design}

One can utilize C++'s inbuilt map as per-thread (independent) hashtables for the LPA algorithm. However, this exhibits poor performance. Therefore, we employ a key-list and a collision-free full-size values array to dramatically improve performance. However, if the memory addresses of the hashtables are nearby (\textit{Close-KV}), even if each thread uses its own hashtable exclusively, the performance is not as high. This is possibly due to false cache-sharing. Alternatively, if we ensure that the memory address of each hashtable is farther away (\textit{Far-KV}), the performance improves. Our results indicate that \textit{Far-KV} has the best performance and is $15.8\times$ times faster than \textit{Map}, and $2.6\times$ times faster than \textit{Close-KV} with LPA. An illustration of \textit{Far-KV} hashtable is in Figure \ref{fig:rak-hashtable}.

\input{src/fig-rak-hashtable}
\input{src/fig-rak-opt}




\subsection{Our optimized LPA implementation}

We now explain the implementation of GVE-LPA in Algorithm \ref{alg:rak}. Its main step is the \texttt{lpa()} function (lines \ref{alg:rak--main-begin}-\ref{alg:rak--main-end}), which takes the input graph $G$ and assigns community memberships (or labels) $C$ to each vertex. In lines \ref{alg:rak--init-begin}-\ref{alg:rak--init-end}, we first initialize the labels $C$ of each vertex in $G$, and mark all vertices as unprocessed. We then perform iterations to propagate labels based on the weighted influence of neighboring vertices, limited to $MAX\_ITERATIONS$ (lines \ref{alg:rak--iters-begin}-\ref{alg:rak--iters-end}). In each iteration, we invoke the \texttt{lpaMove()} function to perform label propagation, and count the number of nodes with updated labels $\Delta N$ (line \ref{alg:rak--propagate}). If the ratio of $\Delta N$ to the total number of nodes $N$ is within a specified tolerance $\tau$, convergence has been achieved, and we terminate the loop (line \ref{alg:rak--converged}). Upon completing all iterations, we return the final labels $C$ (line \ref{alg:rak--main-return}).

\input{src/alg-rak}

The \texttt{lpaMove()} function (lines \ref{alg:rak--move-begin}-\ref{alg:rak--move-end}) iterates over unprocessed vertices in parallel. For each unprocessed vertex $i$ in the graph $G$, we mark $i$ as processed - vertex pruning (line \ref{alg:rak--prune}), obtain the total edge weight of connected labels in per-thread hashtable $H_t$ with the \texttt{scanCommunities()} function \ref{alg:rak--scan}, and select the most weighted label $c^*$ (line \ref{alg:rak--best-community}). If $c^*$ is not the same as the current label of $i$, we update the label of $i$, increment the count of changed vertices $\Delta N$, and mark the neighbors of $i$ as unprocessed for the next iteration (lines \ref{alg:rak--perform-move}-\ref{alg:rak--remark}). After having processed all vertices, we return the total number of vertices with updated labels $\Delta N$ (line \ref{alg:rak--move-return}). The \texttt{scanCommunities()} (lines \ref{alg:rak--scan-begin}-\ref{alg:rak--scan-end}) iterates over the neighbors of the current vertex $i$, excluding itself, and calculates the total weight of each label in the hashtable $H_t$.
